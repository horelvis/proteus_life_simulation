#!/usr/bin/env python3
"""
Test del Sistema de Atenci√≥n Bidireccional
Verifica que cada p√≠xel conoce su contexto completo
"""

import numpy as np
from arc.enhanced_solver_attention import EnhancedSolverWithAttention
from arc.bidirectional_attention import BidirectionalAttentionSystem
import json

def test_bidirectional_context():
    """
    Prueba que los p√≠xeles tienen contexto completo arriba y abajo
    """
    
    print("="*70)
    print("üîÑ TEST DEL SISTEMA DE ATENCI√ìN BIDIRECCIONAL")
    print("="*70)
    
    # Caso de prueba: Expansi√≥n de cruz
    train_examples = [
        {
            "input": [[0, 0, 0], [0, 1, 0], [0, 0, 0]],
            "output": [[0, 1, 0], [1, 1, 1], [0, 1, 0]]
        }
    ]
    
    test_input = np.array([[0, 0, 0], [0, 3, 0], [0, 0, 0]])
    
    # Crear solver con atenci√≥n
    solver = EnhancedSolverWithAttention()
    
    # Resolver con atenci√≥n
    solution, analysis = solver.solve_with_attention(train_examples, test_input)
    
    print("\nüìä AN√ÅLISIS DE LA JERARQU√çA BIDIRECCIONAL")
    print("-"*50)
    
    # Mostrar informaci√≥n de la jerarqu√≠a
    if 'bidirectional_structure' in analysis:
        structure = analysis['bidirectional_structure']
        
        print(f"\nüìç P√≠xeles analizados: {len(structure.get('pixels', {}))}")
        print(f"üî≤ Objetos detectados: {structure.get('num_objects', 0)}")
        print(f"üîó Relaciones encontradas: {structure.get('num_relations', 0)}")
        print(f"üéØ Patrones identificados: {structure.get('num_patterns', 0)}")
    
    # Analizar p√≠xeles espec√≠ficos
    print("\nüîç CONTEXTO COMPLETO DE P√çXELES CLAVE")
    print("-"*50)
    
    # El p√≠xel central debe tener el contexto m√°s rico
    attention_system = solver.attention_system
    
    if attention_system.pixel_layer:
        # P√≠xel central (1, 1)
        center_pixel = attention_system.pixel_layer.get((1, 1))
        
        if center_pixel:
            print(f"\nüìå P√≠xel Central (1, 1):")
            print(f"  Valor: {center_pixel.value}")
            print(f"  Importancia: {center_pixel.importance_score:.2f}")
            
            print(f"\n  ‚¨ÜÔ∏è INFORMACI√ìN TOP-DOWN:")
            print(f"    - Patr√≥n padre: {center_pixel.parent_pattern_id}")
            print(f"    - Rol en patr√≥n: {center_pixel.pattern_role}")
            print(f"    - Valor esperado: {center_pixel.expected_value_from_pattern}")
            
            print(f"\n  ‚¨áÔ∏è INFORMACI√ìN BOTTOM-UP:")
            print(f"    - Objeto padre: {center_pixel.parent_object_id}")
            print(f"    - Rol en objeto: {center_pixel.object_role}")
            print(f"    - Relaci√≥n padre: {center_pixel.parent_relation_id}")
            print(f"    - Rol en relaci√≥n: {center_pixel.relation_role}")
            
            print(f"\n  üîÑ COHERENCIA BIDIRECCIONAL:")
            print(f"    - Soporta patr√≥n: {center_pixel.supports_pattern}")
            print(f"    - Confianza en contexto: {center_pixel.confidence_in_context:.2f}")
            
            # Mostrar contexto completo
            full_context = center_pixel.get_full_context()
            print(f"\n  üìã Contexto Completo:")
            print(json.dumps(full_context, indent=4))
        
        # Analizar p√≠xeles de expansi√≥n
        print("\nüìê P√çXELES DE EXPANSI√ìN:")
        expansion_positions = [(0, 1), (2, 1), (1, 0), (1, 2)]
        
        for x, y in expansion_positions:
            pixel = attention_system.pixel_layer.get((x, y))
            if pixel:
                print(f"\n  P√≠xel ({x}, {y}):")
                print(f"    Valor: {pixel.value}")
                print(f"    Rol objeto: {pixel.object_role}")
                print(f"    Rol patr√≥n: {pixel.pattern_role}")
                print(f"    Importancia: {pixel.importance_score:.2f}")
    
    # Mostrar mapa de atenci√≥n
    if 'attention_map' in analysis and analysis['attention_map']:
        print("\nüó∫Ô∏è MAPA DE ATENCI√ìN:")
        print("-"*50)
        attention_map = np.array(analysis['attention_map'])
        
        print("\nValores de atenci√≥n (0-1):")
        for row in attention_map:
            print("  " + " ".join(f"{val:.2f}" for val in row))
        
        # Encontrar puntos de m√°xima atenci√≥n
        max_attention = np.max(attention_map)
        high_attention_points = np.argwhere(attention_map > max_attention * 0.8)
        
        print(f"\nüéØ Puntos de alta atenci√≥n (>{max_attention*0.8:.2f}):")
        for y, x in high_attention_points:
            print(f"  - Posici√≥n ({x}, {y}): {attention_map[y, x]:.2f}")
    
    # Mostrar insights
    if 'insights' in analysis:
        insights = analysis['insights']
        print("\nüí° INSIGHTS DEL AN√ÅLISIS:")
        print("-"*50)
        print(f"  Atenci√≥n promedio: {insights.get('average_attention', 0):.2f}")
        print(f"  Atenci√≥n m√°xima: {insights.get('max_attention', 0):.2f}")
        print(f"  Score de coherencia: {insights.get('coherence_score', 0):.2f}")
        
        if 'high_attention_points' in insights:
            print(f"\n  üìç Puntos cr√≠ticos detectados: {len(insights['high_attention_points'])}")
            
            for i, point in enumerate(insights['high_attention_points'][:3]):
                print(f"\n  Punto {i+1}: {point['position']}")
                print(f"    Atenci√≥n: {point['attention']:.2f}")
                context = point['context']
                print(f"    Objeto: {context['object']['role']}")
                print(f"    Relaci√≥n: {context['relation']['role']}")
                print(f"    Patr√≥n: {context['pattern']['role']}")
    
    # Verificar la soluci√≥n
    print("\n‚úÖ VERIFICACI√ìN DE LA SOLUCI√ìN:")
    print("-"*50)
    print(f"Input de test:\n{test_input}")
    print(f"\nSoluci√≥n obtenida:\n{solution}")
    
    expected = np.array([[0, 3, 0], [3, 3, 3], [0, 3, 0]])
    print(f"\nSoluci√≥n esperada:\n{expected}")
    
    correct = np.array_equal(solution, expected)
    print(f"\n{'‚úÖ CORRECTO' if correct else '‚ùå INCORRECTO'}")
    
    # Mostrar transformaci√≥n detectada
    if 'transformation_detected' in analysis:
        trans = analysis['transformation_detected']
        print(f"\nüîÑ Transformaci√≥n detectada: {trans.get('type', 'unknown')}")
        print(f"   Confianza: {trans.get('confidence', 0):.2%}")
        
        if 'pattern_type' in trans:
            print(f"   Tipo de patr√≥n: {trans['pattern_type']}")
            print(f"   Confianza del patr√≥n: {trans.get('pattern_confidence', 0):.2%}")
    
    return correct

def test_complex_hierarchy():
    """
    Prueba con un ejemplo m√°s complejo para ver la jerarqu√≠a completa
    """
    
    print("\n" + "="*70)
    print("üèóÔ∏è TEST DE JERARQU√çA COMPLEJA")
    print("="*70)
    
    # Caso con m√∫ltiples objetos y relaciones
    train_examples = [
        {
            "input": [
                [1, 0, 0, 2],
                [1, 0, 0, 2],
                [0, 0, 0, 0],
                [3, 0, 0, 4]
            ],
            "output": [
                [1, 1, 2, 2],
                [1, 1, 2, 2],
                [0, 0, 0, 0],
                [3, 3, 4, 4]
            ]
        }
    ]
    
    test_input = np.array([
        [5, 0, 0, 6],
        [5, 0, 0, 6],
        [0, 0, 0, 0],
        [7, 0, 0, 8]
    ])
    
    solver = EnhancedSolverWithAttention()
    solution, analysis = solver.solve_with_attention(train_examples, test_input)
    
    # Analizar objetos detectados
    attention_system = solver.attention_system
    
    print("\nüî≤ OBJETOS DETECTADOS:")
    print("-"*50)
    
    for obj_id, obj in attention_system.objects.items():
        print(f"\nObjeto #{obj_id}:")
        print(f"  Color: {obj.color}")
        print(f"  Tama√±o: {obj.size} p√≠xeles")
        print(f"  Forma: {obj.shape_type}")
        print(f"  Centro: ({obj.center[0]:.1f}, {obj.center[1]:.1f})")
        print(f"  Relaciones: {obj.parent_relations}")
        print(f"  Patrones: {obj.parent_patterns}")
    
    print("\nüîó RELACIONES DETECTADAS:")
    print("-"*50)
    
    for rel_id, rel in attention_system.relations.items():
        print(f"\nRelaci√≥n #{rel_id}:")
        print(f"  Tipo: {rel.type}")
        print(f"  Objetos: {rel.object_ids}")
        print(f"  Fuerza: {rel.strength:.2f}")
    
    print("\nüéØ PATRONES DETECTADOS:")
    print("-"*50)
    
    for pat_id, pat in attention_system.patterns.items():
        print(f"\nPatr√≥n #{pat_id}:")
        print(f"  Tipo: {pat.type}")
        print(f"  Confianza: {pat.confidence:.2f}")
        print(f"  Objetos involucrados: {pat.child_objects}")
        print(f"  Relaciones involucradas: {pat.child_relations}")
    
    return solution

def main():
    print("="*70)
    print("üß™ SUITE DE TESTS - SISTEMA DE ATENCI√ìN BIDIRECCIONAL")
    print("="*70)
    
    # Test 1: Contexto bidireccional b√°sico
    test1_result = test_bidirectional_context()
    
    # Test 2: Jerarqu√≠a compleja
    test2_result = test_complex_hierarchy()
    
    print("\n" + "="*70)
    print("üìä RESUMEN DE TESTS")
    print("="*70)
    
    print(f"\n‚úÖ Test 1 (Contexto Bidireccional): {'PAS√ì' if test1_result else 'FALL√ì'}")
    print(f"‚úÖ Test 2 (Jerarqu√≠a Compleja): Completado")
    
    print("\nüí° CONCLUSI√ìN:")
    print("El sistema de atenci√≥n bidireccional permite que cada p√≠xel")
    print("conozca su contexto completo en la jerarqu√≠a, desde su rol")
    print("local hasta su participaci√≥n en patrones globales.")

if __name__ == "__main__":
    main()